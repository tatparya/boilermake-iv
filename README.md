# SignLeap

<h3> Boilermake IV Hackathon Project</h3>
<br>
<h3>Objective: American Sign Language -> Text / Audio Conversion</h3>
<h3>Description</h3>
<p>
The application uses a Leap Motion to track the users hand and uses <b>Machine Learning</b> to convert given standard (American Sign Language) hand gestures to text and audio.
</p>
<h3>Progress</h3>
<p>
Given the training set provided, the team was able to demonstrate correct gesture predictions for up to 24 letters and one phrase over 90% of the times
</p>

